{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#RQ: RQ1.1: What are the most important features in detecting PD from speech?\n"
      ],
      "metadata": {
        "id": "6Mz8RtZaTfC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from scipy.stats import entropy\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score"
      ],
      "metadata": {
        "id": "D0kpLyXnQfAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xd85bL4Gtk9",
        "outputId": "81324663-c2d0-49f4-b037-ab4f9cd1607e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# in a code cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 1: extract zip"
      ],
      "metadata": {
        "id": "ghuW8WgQRnGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Italian_Parkinsons_Voice_and_speech.zip'\n",
        "\n",
        "extract_path = '/content/audio_dataset'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "#extract zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "yLt2goSVQNq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 2: list all .wav files recursively"
      ],
      "metadata": {
        "id": "rCBrgIItRqUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define root folder of unzipped data\n",
        "dataset_root = '/content/audio_dataset'\n",
        "\n",
        "# Assign labels\n",
        "label_map = {\n",
        "    '28 People with Parkinson\\'s disease': 1,\n",
        "    '15 Young Healthy Control': 0,\n",
        "    '22 Elderly Healthy Control': 0\n",
        "}\n",
        "\n",
        "# Gather all .wav file paths and corresponding labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for group_folder, label in label_map.items():\n",
        "    group_path = os.path.join(dataset_root, group_folder)\n",
        "    wavs = glob.glob(os.path.join(group_path, '**', '*.wav'), recursive=True)\n",
        "    file_paths.extend(wavs)\n",
        "    labels.extend([label] * len(wavs))\n",
        "\n",
        "print(f'Total files: {len(file_paths)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvoKISIDRut1",
        "outputId": "e00cd073-fa3d-4f8d-d410-40515bfca296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files: 831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 3: train/test split"
      ],
      "metadata": {
        "id": "Z17BgolASJ97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
        "    file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "CfTa3SgPSd7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 4: extract features"
      ],
      "metadata": {
        "id": "n6y2dLE5Snno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(file_path, n_mfcc=13, max_len=100):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    #Pad to fixed length\n",
        "    if mfcc.shape[1] < max_len:\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0,0),(0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "\n",
        "    return mfcc.flatten()\n",
        "\n",
        "# Extract for train and test\n",
        "X_train_mfcc = np.array([extract_mfcc(p) for p in tqdm(X_train_paths)])\n",
        "X_test_mfcc = np.array([extract_mfcc(p) for p in tqdm(X_test_paths)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k37krPZUSjdh",
        "outputId": "5caeaeb2-6e02-48ef-d217-86029132af89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 664/664 [00:53<00:00, 12.51it/s]\n",
            "100%|██████████| 167/167 [00:09<00:00, 17.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_coefficients(coeffs, prefix):\n",
        "    summary = {}\n",
        "    for i, coeff in enumerate(coeffs):\n",
        "        summary[f'{prefix}_{i+1}_mean'] = np.mean(coeff)\n",
        "        summary[f'{prefix}_{i+1}_std'] = np.std(coeff)\n",
        "        summary[f'{prefix}_{i+1}_min'] = np.min(coeff)\n",
        "        summary[f'{prefix}_{i+1}_max'] = np.max(coeff)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "9Kbej2SKo1e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfb(file_path, n_mels=40):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    y = librosa.util.normalize(y)\n",
        "\n",
        "    # Mel Filter Banks (MFB)\n",
        "    mel_spec = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr, n_fft=2048, hop_length=512,\n",
        "        n_mels=n_mels, fmin=0, fmax=sr // 2\n",
        "    )\n",
        "    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Summarize (e.g., mean, std, skewness, etc.)\n",
        "    mfb_summary = summarize_coefficients(log_mel_spec, \"mfb\")\n",
        "\n",
        "    return mfb_summary"
      ],
      "metadata": {
        "id": "znw6PI2nDUey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mfb_df = pd.DataFrame([extract_mfb(p) for p in tqdm(X_train_paths)])\n",
        "X_test_mfb_df = pd.DataFrame([extract_mfb(p) for p in tqdm(X_test_paths)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57i8-otsccGK",
        "outputId": "17d9f0ce-2e60-454c-85ee-f85149d67c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 664/664 [00:32<00:00, 20.73it/s]\n",
            "100%|██████████| 167/167 [00:07<00:00, 22.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize entropy features\n",
        "def summarize_entropy(signal, sr, frame_length=2048, hop_length=512, n_bins=30):\n",
        "    frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length)\n",
        "    time_entropy = []\n",
        "    for frame in frames.T:\n",
        "        hist, _ = np.histogram(np.abs(frame), bins=n_bins, density=True)\n",
        "        hist += 1e-10\n",
        "        time_entropy.append(entropy(hist, base=2))\n",
        "    return {\n",
        "        'entropy_mean': np.mean(time_entropy),\n",
        "        'entropy_std': np.std(time_entropy),\n",
        "        'entropy_min': np.min(time_entropy),\n",
        "        'entropy_max': np.max(time_entropy)\n",
        "    }\n",
        "\n",
        "# Extract entropy feature\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    y = librosa.util.normalize(y)\n",
        "    entropy_summary = summarize_entropy(y, sr)\n",
        "    return entropy_summary\n",
        "\n",
        "# Apply feature extraction to train/test sets\n",
        "X_train_entropy = [extract_features(p) for p in tqdm(X_train_paths)]\n",
        "X_test_entropy = [extract_features(p) for p in tqdm(X_test_paths)]\n",
        "\n",
        "X_train_entropy_df = pd.DataFrame(X_train_entropy)\n",
        "X_test_df = pd.DataFrame(X_test_entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M195RTuMNoR",
        "outputId": "d2c0eaad-f03f-4a62-981c-eb08296886c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 664/664 [05:24<00:00,  2.04it/s]\n",
            "100%|██████████| 167/167 [01:36<00:00,  1.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train SVM"
      ],
      "metadata": {
        "id": "vjPAp8F6Qsp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='rbf', C=1, gamma='scale')\n",
        "clf.fit(X_train_mfcc, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test_mfcc)\n",
        "print(\"SVM statistics mfcc\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG04xGibQxjN",
        "outputId": "4fcc7bb4-9ea8-40ab-96a7-a4691a89b02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM statistics mfcc\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91        79\n",
            "           1       0.91      0.93      0.92        88\n",
            "\n",
            "    accuracy                           0.92       167\n",
            "   macro avg       0.92      0.92      0.92       167\n",
            "weighted avg       0.92      0.92      0.92       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='rbf', C=1, gamma='scale')\n",
        "clf.fit(X_train_mfb_df, y_train)\n",
        "y_pred = clf.predict(X_test_mfb_df)\n",
        "\n",
        "print(\"SVM statistics mfb\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du6mr92yb_Rx",
        "outputId": "b416d338-db61-4b8c-a7d2-eb0c6ea5ad1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM statistics mfb\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        79\n",
            "           1       0.94      0.97      0.96        88\n",
            "\n",
            "    accuracy                           0.95       167\n",
            "   macro avg       0.95      0.95      0.95       167\n",
            "weighted avg       0.95      0.95      0.95       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm.fit(X_train_entropy_df, y_train)\n",
        "y_pred = svm.predict(X_test_df)\n",
        "\n",
        "print(\"SVM statistics time entropy\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiJB6MPKPdx5",
        "outputId": "3712447f-b8a6-43fc-aa4e-c6f95a717e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM statistics time entropy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.63      0.60        79\n",
            "           1       0.64      0.58      0.61        88\n",
            "\n",
            "    accuracy                           0.60       167\n",
            "   macro avg       0.61      0.61      0.60       167\n",
            "weighted avg       0.61      0.60      0.60       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Random Forest Classifier"
      ],
      "metadata": {
        "id": "QFXyPyFnW67D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "NWCDodzvYhwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest on MFCC features\n",
        "rf_mfcc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_mfcc.fit(X_train_mfcc, y_train)\n",
        "y_pred_mfcc = rf_mfcc.predict(X_test_mfcc)\n",
        "print(\"Random Forest statistics MFCC\")\n",
        "print(classification_report(y_test, y_pred_mfcc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AT6lS5ZYlXM",
        "outputId": "3a2a44f1-e270-4896-9431-f59500f2b6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest statistics MFCC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97        79\n",
            "           1       0.97      0.99      0.98        88\n",
            "\n",
            "    accuracy                           0.98       167\n",
            "   macro avg       0.98      0.98      0.98       167\n",
            "weighted avg       0.98      0.98      0.98       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest on MFB features\n",
        "rf_mfb = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_mfb.fit(X_train_mfb_df, y_train)\n",
        "y_pred_mfb = rf_mfb.predict(X_test_mfb_df)\n",
        "print(\"Random Forest statistics MFB\")\n",
        "print(classification_report(y_test, y_pred_mfb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-W_2fGXYodn",
        "outputId": "8dfec83a-f4d2-4c1a-b874-e3f456498d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest statistics MFB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        79\n",
            "           1       1.00      0.99      0.99        88\n",
            "\n",
            "    accuracy                           0.99       167\n",
            "   macro avg       0.99      0.99      0.99       167\n",
            "weighted avg       0.99      0.99      0.99       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest on time entropy features\n",
        "rf_entropy = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_entropy.fit(X_train_entropy_df, y_train)\n",
        "y_pred_entropy = rf_entropy.predict(X_test_df)\n",
        "print(\"Random Forest statistics Time Entropy\")\n",
        "print(classification_report(y_test, y_pred_entropy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsbFzLLYtKG",
        "outputId": "309d39fb-faad-4dc4-9a09-8bdf2d49f181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest statistics Time Entropy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.70      0.75        79\n",
            "           1       0.76      0.86      0.81        88\n",
            "\n",
            "    accuracy                           0.78       167\n",
            "   macro avg       0.79      0.78      0.78       167\n",
            "weighted avg       0.79      0.78      0.78       167\n",
            "\n"
          ]
        }
      ]
    }
  ]
}